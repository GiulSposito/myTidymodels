---
title: "Dimensionality Reduction"
output: 
  md_document:
    toc: yes
editor_options: 
  chunk_output_type: console
---

## Main objetives

1. Demonstrate how to use recipes to create a small set of features that capture the main aspects of the original predictor set.
2. Descrive how recipes can be used on their own (as opposed to being used in a workflow object)

In addition to the tidymodels package, this chapter uses the following packages: `baguette`, `beans`, `bestNormalize`, `corrplot`, `discrim`, `embed`, `ggforce`, `klaR`, `learntidymodels`, `mixOmics`, and `uwot.`

## Beans dataset

```{r}
# put rnotbook in the same workdir
knitr::opts_knit$set(root.dir = normalizePath(rprojroot::find_rstudio_root_file())) 
library(tidymodels)
library(beans)
data("beans")

# what we have here?
beans |> 
  skimr::skim()

# split (with a validation set)
set.seed(1601)
bean_split <- initial_validation_split(beans, strata = class,
                                       prop = c(.75, .125))

bean_split

# the dataframes
bean_train <- training(bean_split) 
bean_test  <- testing(bean_split) 
bean_validation <- validation(bean_split)

# create a rset for tunning
set.seed(1601)
bean_val <- validation_set(bean_split)
bean_val
bean_val$splits[[1]]
```

To visually assess how well different methods perform, we can estimate the methods on the training set (n = 10,206 beans) and display the results using the validation set (n = 1,702).

Before beginning any dimensionality reduction, we can spend some time investigating our data. Since we know that many of these shape features are probably measuring similar concepts, let’s take a look at the correlation structure of the data using this code.

```{r}
library(corrplot)

tmwr_cols <- colorRampPalette(c("#91CBD765", "#CA225E"))

bean_train |> 
  select(-class) |> 
  cor() |> 
  corrplot(col=tmwr_cols(200), tl.col="black")
```

Many of these predictors are highly correlated, such as area and perimeter or shape factors 2 and 3.

## A STARTER RECIPE

Several predictors are ratios and so are likely to have skewed distributions. Such distributions can wreak havoc on variance calculations (such as the ones used in PCA). The `bestNormalize` package has a step that can enforce a symmetric distribution for the predictors. We’ll use this to mitigate the issue of skewed distributions:

```{r}
library(bestNormalize)

bean_rec <- 
  recipe(class ~ ., data=bean_train) |> 
  step_zv(all_numeric_predictors()) |> 
  step_orderNorm(all_numeric_predictors()) |> 
  step_normalize(all_numeric_predictors())

bean_rec


# training the recipe
bean_rec_trained <- prep(bean_rec)
bean_rec_trained

```

> Remember that `prep()` for a recipe is like `fit() `for a model.

## BACKING THE RECIPE

> Using `bake()` with a recipe is much like using `predict()` with a model; the operations estimated from the training set are applied to any data, like testing data or new data at prediction time.

```{r}
bean_val_processed <- bake(bean_rec_trained, new_data = bean_validation)

library(patchwork)
p1 <- bean_validation |> 
  ggplot(aes(x=area)) +
  geom_histogram(bins=30, color="white", fill="blue", alpha=1/3) +
  ggtitle("Original validation set data")

p2 <- bean_val_processed |> 
  ggplot(aes(x=area)) +
  geom_histogram(bins=30, color="white", fill="red", alpha=1/3) +
  ggtitle("Processed validation set data")

p1+p2
  
```


## Feature Extraction Techniques

Since recipes are the primary option in tidymodels for dimensionality reduction, let’s write a function that will estimate the transformation and plot the resulting data in a scatter plot matrix via the ggforce package:

```{r}
library(ggforce) 

plot_validation_results <- function(recipe, dat=bean_validation){
  recipe |> 
    prep() |> 
    bake(new_dat=dat) |> 
    ggplot(aes(.panel_x, y=.panel_y, color=class, fill=class)) +
    geom_point(alpha = 0.4, size=0.5) +
    geom_autodensity(alpha=.3) +
    facet_matrix(vars(-class), layer.diag = 2) +
    scale_color_brewer(palette="Dark2") +
    scale_fill_brewer(palette="Dark2") +
    theme_light()
}
```

## PCA

```{r}

bean_rec_trained |> 
  step_pca(all_numeric_predictors(), num_comp=4) |> 
  plot_validation_results() +
  ggtitle("Principal Component Analysis")

```


We see that the first two components PC1 and PC2, especially when used together, do an effective job distinguishing between or separating the classes. Recall that PCA is unsupervised. For these data, it turns out that the PCA components that explain the most variation in the predictors also happen to be predictive of the classes.

What features are driving performance? The `learntidymodels` package has functions that can help visualize the top features for each component. We’ll need the prepared recipe; the PCA step is added in the following code along with a call to `prep()`:

```{r}
library(learntidymodels)

bean_rec_trained |> 
  step_pca(all_numeric_predictors(), num_comp=4) |> 
  prep() |> 
  plot_top_loadings(component_number <=4, n=5) +
  scale_fill_brewer(palette="Paired") +
  theme_light() +
  ggtitle("Principal Component Analysis")
  
```

## Partial Least Squares

PLS is a supervised version of PCA. It tries to find components that simultaneously maximize the variation in the predictors while also maximizing the relationship between those components and the outcome

```{r}
bean_rec_trained |> 
  step_pls(all_numeric_predictors(), outcome="class", num_comp=4) |> 
  plot_validation_results() +
  ggtitle("Partial Least Squares")
```


The first two PLS components plotted in Figure 16.7 are nearly identical to the first two PCA components! We find this result because those PCA components are so effective at separating the varieties of beans. The remaining components are different.


```{r}
bean_rec_trained |> 
  step_pls(all_numeric_predictors(), outcome="class", num_comp=4) |> 
  prep() |> 
  plot_top_loadings(component_number <= 4, n=5, type="pls") +
  scale_fill_brewer(palette="Paired") +
  ggtitle("Partial Least Squares")
```

_Solidity_ (i.e., the density of the bean) drives the third PLS component, along with roundness. _Solidity_ may be capturing bean features related to “bumpiness” of the bean surface since it can measure irregularity of the bean boundaries.

## Independent Component Analysis

ICA is slightly different than PCA in that if finds components that are statistically independent from one another possible (as opposed to being uncorrelated). It can be thought of as maximizing the "non gaussianity" of the ICA components, or separating information instead of compressing information like PCA.

```{r}
bean_rec_trained |> 
  step_ica(all_numeric_predictors(), num_comp=4) |> 
  plot_validation_results() +
  ggtitle("Independent Component Analysis")
```

Inspecting this plot, there does not appear to be much separation between the classes in the first few components when using ICA. These independent (or as independent as possible) components do not separate the bean types.

## Uniform Manifold Approximation and Projection

UMAP is similar to the popular t-SNE method for nonlinear dimension reduction. In the original high-dimensional space, UMAP uses a distance-based nearest neighbor method to find local areas of the data where the data points are more likely to be related. The relationship between data points is saved as a directed graph model where most points are not connected.

From there, UMAP translates points in the graph to the reduced dimensional space. To do this, the algorithm has an optimization process that uses cross-entropy to map data points to the smaller set of features so that the graph is well approximated.

```{r}
library(embed)
bean_rec_trained |> 
  step_umap(all_numeric_predictors(), num_comp=4) |> 
  plot_validation_results() +
  ggtitle("UMAP")
```

While the between-cluster space is pronounced, the clusters can contain a heterogeneous mixture of classes.

There is also a supervised version of UMAP:

```{r}
bean_rec_trained |> 
  step_umap(all_numeric_predictors(), outcome="class", num_comp=4) |> 
  plot_validation_results() +
  ggtitle("UMAP (supervisioned)")
```

UMAP is a powerful method to reduce the feature space. However, it can be very sensitive to tuning parameters. For this reason, it would help to experiment with a few of the parameters to assess how robust the results are for these data.


## Modeling

Both the PLS and UMAP methods are worth investigating in conjunction with different models. Let’s explore a variety of different models with these dimensionality reduction techniques (along with no transformation at all): a single layer neural network, bagged trees, flexible discriminant analysis (FDA), naive Bayes, and regularized discriminant analysis (RDA).

```{r}
library(baguette)
library(discrim)

mlp_spec <- 
  mlp(hidden_units = tune(), penalty=tune(), epochs=tune()) |> 
  set_engine("nnet") |> 
  set_mode("classification")

bagging_spec <- 
  bag_tree() |> 
  set_engine("rpart") |> 
  set_mode("classification")

fda_spec <- 
  discrim_flexible(prod_degree = tune()) |> 
  set_engine("earth")

rda_spec <- 
  discrim_regularized(frac_common_cov=tune(), frac_identity=tune()) |> 
  set_engine("klaR")

bayes_spec <- 
  naive_Bayes() |> 
  set_engine("klaR")
```

We also need recipes for the dimensionality reduction methods we’ll try. Let’s start with a base recipe `bean_rec` and then extend it with different dimensionality reduction steps:

```{r}
bean_rec <- 
  recipe(class ~ ., data=bean_train) |> 
  step_zv(all_numeric_predictors()) |> 
  step_orderNorm(all_numeric_predictors()) |> 
  step_normalize(all_numeric_predictors())

pls_rec <- 
  bean_rec |> 
  step_pls(all_numeric_predictors(), outcome = "class", num_comp=tune())

umap_rec <-
  bean_rec |> 
  step_umap(all_numeric_predictors(),
            outcome = "class",
            num_comp = tune(), 
            neighbors = tune(),
            min_dist = tune())

pca_rec <- 
  bean_rec |> 
  step_pca(num_comp = tune())
```

Once again, the `workflowsets` package takes the preprocessors and models and crosses them. The control option parallel_over is set so that the parallel processing can work simultaneously across tuning parameter combinations.

```{r cache=TRUE, eval=FALSE}
ctrl <- control_grid(parallel_over = "everything")

library(doMC)
registerDoMC()

bean_res <- 
  workflow_set(
    preproc = list(basic=class~., pls=pls_rec, umap=umap_rec, pca=pca_rec),
    models  = list(bayes=bayes_spec, fda=fda_spec,
                   rda=rda_spec, bag=bagging_spec,
                   mlp=mlp_spec)) |> 
  workflow_map(
    verbose = T,
    seed = 1603,
    resamples = bean_val, 
    grid = 10,
    metrics = metric_set(roc_auc),
    control = ctrl
  )

saveRDS(bean_res, "./tmwr/chp16_bean_res.rds")
```

We can rank the models by their validation set, estimates of the area under the ROC curve:

```{r}
bean_res <- readRDS("./tmwr/chp16_bean_res.rds") 

rankings <- 
  bean_res |> 
  rank_results(select_best=T) |> 
  mutate(method = map_chr(wflow_id, ~str_split(.x, "_", simplify=T)[1]))

rankings |> 
  filter(rank<=5) |> 
  dplyr::select(rank, mean, model, method)
```

```{r}
rankings |> 
  ggplot(aes(x=rank, y=mean, color=model, shape=method)) +
  geom_point(size=3) +
  geom_text(aes(label=wflow_id), angle=90, hjust=1, nudge_y = -.004) +
  labs(
    title="Model + Reduc Dim Method Performance",
    x="Rank",
    y="ROC AUC"
  ) +
  lims(y=c(.91,NA)) +
  theme_light()
```

For demonstration, we`ll use the best result as final model. We finalize the workflow with the numerically best parameters, fit it to the training set, then evaluate with the test set:

```{r}
best_model_method <- rankings[1,]$wflow_id
best_model_method

best_res <- 
  bean_res |> 
  extract_workflow(best_model_method) |> 
  finalize_workflow(
    bean_res |> 
      extract_workflow_set_result(best_model_method) |> 
      select_best(metric="roc_auc")
  ) |> 
  last_fit(split=bean_split, metrics=metric_set(roc_auc))

best_wflow_fit <- extract_workflow(best_res)
  
```

What are the results for our metric on testing set?

```{r}
collect_metrics(best_res)
```

Pretty good! We’ll use this model in the next chapter to demonstrate variable importance methods.

# Reference

All code and text came from Max Kuhn and Julia Silge`s book [Tidy Modeling with R](https://www.tmwr.org/dimensionality).






















