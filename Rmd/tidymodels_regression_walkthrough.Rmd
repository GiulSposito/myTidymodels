---
title: "Tidymodels Regression Walkthrought"
subtitle: "using tidymodel"
author: "Giuliano Sposito"
output:
  md_document:
    variant: markdown_github
---

# Intro

This notebook tells the basic steps to ML pipeline using [`{tidymodels}`](https://www.tidymodels.org/) packages, we'll do a regression case and a classification case.

The traditional (without tunning) step for a ML pipeline are: 

1. Split the dataset between Training and Testing subsets ([`{rsample}`](https://rsample.tidymodels.org/))
1. Preprocessing and Feature Eng [`{recipes}`](https://recipes.tidymodels.org/)
1. Train a model ([`{parnsip}`](https://parsnip.tidymodels.org/)) using training dataset
1. Predict the outcome using the test dataset
1. Eval the model performance ([`{yardstick}`](https://yardstick.tidymodels.org/))

In this notebook we won't use the [`{workflow}`](https://workflows.tidymodels.org/) package, to understand the building blocks of 
[`{tidymodels}`](https://www.tidymodels.org/).

# Regression Example

## 1. training and testing datasets

```{r regSplit, message=FALSE, warning=FALSE}
# tidymodel package to split datasets (tr/ts, CV,...)
library(rsample) 

# rsample::initial_split
cars_split <- initial_split(mtcars, prop = .75)

# `rsplit` object: <training/test/total>
cars_split

# getting the slices
trn_cars <- training(cars_split)
tst_cars <- testing(cars_split)
```

## 2. Preprocessing and Feature Eng

```{r regRecp, message=FALSE, warning=FALSE}
# tidymodel package to specify a sequence of transformation steps
library(recipes)

# recipe
cars_recipe <- trn_cars %>%         # base dataset
  recipe(mpg ~ .) %>%               # recipe with formula
  step_corr(all_predictors()) %>%   # remove variables with large correlations 
  step_center(all_predictors()) %>% # normalize numeric data to have a mean of zero
  step_scale(all_predictors()) %>%  # normalize data to have a standard deviation of one
  # estimate the required parameters from a training set
  # that can be later applied to other data sets.
  prep()


# recipe object
cars_recipe
```


```{r regRecpExplore, message=FALSE, warning=FALSE}

# we can get the transformed training set using `juice(recipe)`
cars_training <- juice(cars_recipe)
head(cars_training)

# we can apply the transformation on the test set using `bake(recipe, new_data)`
cars_testing <- bake(cars_recipe, tst_cars)
head(cars_testing)

```


## 3. Training a model

```{r regTrain, message=FALSE, warning=FALSE}
# tidymodel package the uniforms the machine learnings algorithm interface
library(parsnip) # parsnip is the caret successor

cars_lm <- parsnip::linear_reg() %>% # interface to linear models
  set_engine("lm") %>%               # using traditional R's lm as engine
  fit(mpg ~ ., data=cars_training)   # fit the model using transformed training set

# parsnip object
cars_lm

```
```{r regParsnipExplore, message=FALSE, warning=FALSE}

# getting the real model (lm) inside parsnip
summary(cars_lm$fit)

```

## 4. Prediction

```{r regPred, message=FALSE, warning=FALSE}

y_hat <- predict(cars_lm, cars_testing)
head(y_hat)

```

## 5. Evaluate Model Performance

```{r, message=FALSE, warning=FALSE}
# tidymodel package for measuring model performances
library(yardstick)

y_hat %>%                               
  bind_cols(cars_testing) %>%        # binds prediction to the real data
  metrics(truth=mpg, estimate=.pred) # use yardstick::metrics to get the evalution metrics

```

## Bonus: Changing the model and checking for a better performance

```{r regBonus, message=FALSE, warning=FALSE}

# Bonus: testing another model
cars_rf <- rand_forest(trees = 100, mode="regression") %>% # random forest
  set_engine("ranger") %>%                                 # ranger algo
  fit(mpg ~ ., data=cars_training)                         # fit the model  

# parsnip object
cars_rf

# check if fits better
predict(cars_rf, cars_testing) %>% 
  bind_cols(cars_testing) %>% 
  metrics(truth=mpg, estimate = .pred)

```

## Regression Full Code

```{r regFullCode, eval=FALSE}

## 1. training and testing datasets

# tidymodel package to split datasets (tr/ts, CV,...)
library(rsample) 

# rsample::initial_split
cars_split <- initial_split(mtcars, prop = .75)

# `rsplit` object: <training/test/total>
cars_split

# getting the slices
trn_cars <- training(cars_split)
tst_cars <- testing(cars_split)


## 2. Preprocessing and Feature Eng

# tidymodel package to specify a sequence of transformation steps
library(recipes)

# recipe
cars_recipe <- trn_cars %>%         # base dataset
  recipe(mpg ~ .) %>%               # recipe with formula
  step_corr(all_predictors()) %>%   # remove variables with large correlations 
  step_center(all_predictors()) %>% # normalize numeric data to have a mean of zero
  step_scale(all_predictors()) %>%  # normalize data to have a standard deviation of one
  # estimate the required parameters from a training set
  # that can be later applied to other data sets.
  prep()


# recipe object
cars_recipe


# we can get the transformed training set using `juice(recipe)`
cars_training <- juice(cars_recipe)
head(cars_training)

# we can apply the transformation on the test set using `bake(recipe, new_data)`
cars_testing <- bake(cars_recipe, tst_cars)
head(cars_testing)



## 3. Training a model

# tidymodel package the uniforms the machine learnings algorithm interface
library(parsnip) # parsnip is the caret successor

cars_lm <- parsnip::linear_reg() %>% # interface to linear models
  set_engine("lm") %>%               # using traditional R's lm as engine
  fit(mpg ~ ., data=cars_training)   # fit the model using transformed training set

# parsnip object
cars_lm


# getting the real model (lm) inside parsnip
summary(cars_lm$fit)


## 4. Prediction

y_hat <- predict(cars_lm, cars_testing)
head(y_hat)

## 5. Evaluate Model Performance

# tidymodel package for measuring model performances
library(yardstick)

y_hat %>%                               
  bind_cols(cars_testing) %>%        # binds prediction to the real data
  metrics(truth=mpg, estimate=.pred) # use yardstick::metrics to get the evalution metrics


## Bonus: Changing the model and checking for a better performance

# Bonus: testing another model
cars_rf <- rand_forest(trees = 100, mode="regression") %>% # random forest
  set_engine("ranger") %>%                                 # ranger algo
  fit(mpg ~ ., data=cars_training)                         # fit the model  

# parsnip object
cars_rf

# check if fits better
predict(cars_rf, cars_testing) %>% 
  bind_cols(cars_testing) %>% 
  metrics(truth=mpg, estimate = .pred)

```

